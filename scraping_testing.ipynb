{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup, element\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Clear any existing logging handlers\n",
    "logger = logging.getLogger()\n",
    "for handler in logger.handlers:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "# Configure logging to display log messages in the notebook\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "# scraping\n",
    "def scrape_webpage(url: str) -> bytes | None:\n",
    "    \"\"\"\n",
    "    Fetches the content of a webpage.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): The URL of the webpage to scrape.\n",
    "\n",
    "    Returns:\n",
    "        bytes | None: The raw content of the webpage if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Attempting to fetch content from {url}\")\n",
    "        page = requests.get(url)\n",
    "        page.raise_for_status()\n",
    "        logger.info(f\"Successfully fetched content from {url}\")\n",
    "        return page.content\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        logger.error(f\"An error occurred while fetching content from {url}: {e}\")\n",
    "\n",
    "def has_content(page_content: bytes) -> bool:\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    if soup.find('div', {'class': 'greyText nocontent stacked'}):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def scrape_webpage_paginate(review_list_number: int, sec_sleep_between_scraping: float = 2) -> list[bytes]:\n",
    "    scraped_webpages = []\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        url = f'https://www.goodreads.com/review/list/{review_list_number}?page={page_number}&ref=nav_mybooks'\n",
    "        page_content = scrape_webpage(url)\n",
    "        \n",
    "        if not has_content(page_content):\n",
    "            logger.info(f\"Scraping is done as no more content could be found after scraping {page_number} pages.\")\n",
    "            break\n",
    "\n",
    "        scraped_webpages.append(page_content)\n",
    "        \n",
    "        time.sleep(sec_sleep_between_scraping)\n",
    "        page_number += 1\n",
    "    return scraped_webpages\n",
    "\n",
    "    \n",
    "# utilities\n",
    "def parse_scraped_reviews(scraped_webpages: list[bytes]) -> pd.DataFrame:\n",
    "    reviews: list = []\n",
    "    for webpage_content in scraped_webpages:\n",
    "        soup = BeautifulSoup(webpage_content, 'html.parser')\n",
    "        reviews_html_format = soup.find_all(class_='bookalike review')\n",
    "        for review in reviews_html_format:\n",
    "            review_dict = parse_review(review)\n",
    "            reviews.append(review_dict)\n",
    "    return pd.DataFrame.from_dict(reviews)\n",
    "\n",
    "    \n",
    "def parse_review(review: element.Tag) -> dict:\n",
    "    return {\n",
    "        'title': get_review_title(review),\n",
    "        'avg_rating': get_review_average_rating(review),\n",
    "        'given_rating': get_review_given_rating(review),\n",
    "            }\n",
    "\n",
    "def get_review_title(review: element.Tag) -> str:\n",
    "    return review.find('td', class_='field title').find('a').text.strip()\n",
    "\n",
    "def get_review_average_rating(review: element.Tag) -> float:\n",
    "    return float(review.find('td', {'class': 'field avg_rating'}).find('div', {'class': 'value'}).text.strip())\n",
    "\n",
    "def ratings_mapping() -> defaultdict:\n",
    "    ratings_mapping = defaultdict(lambda: None)\n",
    "    ratings_mapping.update({'it was amazing': 5,\n",
    "                        'really liked it': 4,\n",
    "                        'liked it': 3,\n",
    "                        'it was ok': 2,\n",
    "                        'did not like it': 1,})\n",
    "    return ratings_mapping\n",
    "\n",
    "def get_review_given_rating(review: element.Tag) -> int:\n",
    "    span_tag = review.find('span', {'class': 'staticStars notranslate'})\n",
    "    title_value = span_tag['title'] if 'title' in span_tag.attrs else None\n",
    "    return ratings_mapping()[title_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=1&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=1&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=1&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=1&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=2&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=2&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=2&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=2&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=3&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=3&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=3&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=3&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=4&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=4&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=4&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=4&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=5&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=5&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=5&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=5&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=6&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=6&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=6&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=6&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=7&ref=nav_mybooks\n",
      "Attempting to fetch content from https://www.goodreads.com/review/list/54144458?page=7&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=7&ref=nav_mybooks\n",
      "Successfully fetched content from https://www.goodreads.com/review/list/54144458?page=7&ref=nav_mybooks\n",
      "Scraping is done as no more content could be found after scraping 7 pages.\n",
      "Scraping is done as no more content could be found after scraping 7 pages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "scraped_webpages = scrape_webpage_paginate(54144458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reviews = parse_scraped_reviews(scraped_webpages)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully saved DataFrame to keke.pkl.\n",
      "Successfully saved DataFrame to keke.pkl.\n"
     ]
    }
   ],
   "source": [
    "def save_dataframe_to_pickle(df: pd.DataFrame, save_name: str) -> None:\n",
    "    try:\n",
    "        df.to_pickle(f\"{save_name}.pkl\")\n",
    "        logging.info(f\"Successfully saved DataFrame to {save_name}.pkl.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while saving the DataFrame: {e}\")\n",
    "save_dataframe_to_pickle(reviews, \"keke\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b892c7c4839e935d45d7735e64d33d791024a1cde9db440c52f5d7dc395fe3f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
